{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633eaac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\krupe\\OneDrive\\Desktop\\Sentiment\\vaccination_all_tweets.csv\")\n",
    "\n",
    "#Data Preprocessing\n",
    "text_df = df.drop(['id', 'user_name', 'user_location', 'user_description', 'user_created',\n",
    "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
    "       'date', 'hashtags', 'source', 'retweets', 'favorites',\n",
    "       'is_retweet'], axis=1)\n",
    "\n",
    "#Cleansing strings\n",
    "def data_processing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https\\S+|www\\S+https\\S+\", '',text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@w+|\\#','',text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    filtered_text = [w for w in text_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "text_df.text = text_df['text'].apply(data_processing)\n",
    "\n",
    "#Stemming Words\n",
    "stmpred = PorterStemmer()\n",
    "def stemming_frame(data):\n",
    "    l = len(data)\n",
    "    for i in range(0,l,1):\n",
    "        txt = []\n",
    "        list = data[i].split(\" \")\n",
    "    \n",
    "    \n",
    "        for w in list:\n",
    "            a = stmpred.stem(w)\n",
    "            txt.append(a)\n",
    "            textprocessed = ' '.join(map(str,txt))\n",
    "        data[i] = textprocessed\n",
    "stemming_frame(text_df['text'])\n",
    "    \n",
    "#Polarity of Strings\n",
    "def polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "text_df['polarity'] = text_df['text'].apply(polarity)\n",
    "\n",
    "#Sentiment Labelling\n",
    "def sentiment(label):\n",
    "    if label <0:\n",
    "        return \"Negative\"\n",
    "    elif label ==0:\n",
    "        return \"Neutral\"\n",
    "    elif label>0:\n",
    "        return \"Positive\"\n",
    "text_df['sentiment'] = text_df['polarity'].apply(sentiment)\n",
    "\n",
    "#Dropping Duplicate Tweets\n",
    "text_df = text_df.drop_duplicates('text')\n",
    "\n",
    "#Dropping Polarity\n",
    "text_df = text_df.drop(['polarity'],axis=1)\n",
    "\n",
    "#Save Processed Dataframe to CSV\n",
    "\n",
    "text_df.to_csv(r\"C:\\Users\\krupe\\OneDrive\\Desktop\\Sentiment\\Final.csv\")\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11e93463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\krupe\\OneDrive\\Desktop\\Sentiment\\Final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0368b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer(ngram_range=(1,2)).fit(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c79a6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 803546\n",
      "\n",
      "First 20 features:\n",
      " ['00' '00 dose' '000' '000 00' '000 000the' '000 717' '000 belgium'\n",
      " '000 covid19' '000 death' '000 donat' '000 dose' '000 first' '000 half'\n",
      " '000 health' '000 initi' '000 peopl' '000 purchas' '000 sha' '000 share'\n",
      " '000 sinopharm']\n"
     ]
    }
   ],
   "source": [
    "feature_names =vectoriser.get_feature_names_out()\n",
    "print(\"Number of features: {}\\n\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n {}\".format(feature_names[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68745d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "Y = df['sentiment']\n",
    "X = vectoriser.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9868be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         folk said daikon past could treat cytokin stor...\n",
      "1         world wrong side histori year hope biggest vac...\n",
      "2         coronaviru sputnikv astrazeneca pfizerbiontech...\n",
      "3         fact immut senat even your ethic sturdi enough...\n",
      "4         explain need vaccin borisjohnson matthancock w...\n",
      "                                ...                        \n",
      "211525    45 urban bengaluru covidvaccin avail 1511 0230...\n",
      "211526    1844 bbmp bengaluru covidvaccin avail 1511 020...\n",
      "211527    1844 urban bengaluru covidvaccin avail 1511 02...\n",
      "211528    promot vaccin leav stronger russia vaccin sput...\n",
      "211529    45 urban bengaluru covidvaccin avail 1511 0130...\n",
      "Name: text, Length: 211530, dtype: object\n",
      "  (0, 724810)\t0.287984170255165\n",
      "  (0, 724788)\t0.19233937752503638\n",
      "  (0, 679565)\t0.287984170255165\n",
      "  (0, 679555)\t0.22921529381984124\n",
      "  (0, 618999)\t0.287984170255165\n",
      "  (0, 618772)\t0.12527791376881747\n",
      "  (0, 547348)\t0.10173962790381616\n",
      "  (0, 537995)\t0.27869403407063364\n",
      "  (0, 537957)\t0.17265053773120206\n",
      "  (0, 308744)\t0.287984170255165\n",
      "  (0, 308580)\t0.17085679781841123\n",
      "  (0, 223632)\t0.287984170255165\n",
      "  (0, 223631)\t0.287984170255165\n",
      "  (0, 223063)\t0.2721025775495159\n",
      "  (0, 223062)\t0.2721025775495159\n",
      "  (0, 197504)\t0.287984170255165\n",
      "  (0, 196986)\t0.13829673011615765\n",
      "  (1, 793977)\t0.26003521240505184\n",
      "  (1, 793638)\t0.12159636377408144\n",
      "  (1, 790993)\t0.26922717654293504\n",
      "  (1, 790859)\t0.17485619478987408\n",
      "  (1, 788387)\t0.28494094302634404\n",
      "  (1, 787523)\t0.11666090074467271\n",
      "  (1, 779602)\t0.28494094302634404\n",
      "  (1, 779576)\t0.18356811807983753\n",
      "  :\t:\n",
      "  (211528, 427161)\t0.25929190571259697\n",
      "  (211529, 740648)\t0.1816963770906705\n",
      "  (211529, 740639)\t0.18021995882084055\n",
      "  (211529, 656750)\t0.1688978487914566\n",
      "  (211529, 656647)\t0.15247635443953617\n",
      "  (211529, 656559)\t0.19988780494108702\n",
      "  (211529, 532119)\t0.1687306538120043\n",
      "  (211529, 531970)\t0.16546231610212564\n",
      "  (211529, 313916)\t0.150163086654049\n",
      "  (211529, 313516)\t0.14413125094073045\n",
      "  (211529, 255377)\t0.1564752385420486\n",
      "  (211529, 215221)\t0.19674870546565584\n",
      "  (211529, 214875)\t0.13243804027755707\n",
      "  (211529, 213102)\t0.15010244582243648\n",
      "  (211529, 212970)\t0.12598299183594275\n",
      "  (211529, 128223)\t0.15021370421611538\n",
      "  (211529, 128199)\t0.14972090203754876\n",
      "  (211529, 114393)\t0.3111030798306004\n",
      "  (211529, 114306)\t0.13641741013215083\n",
      "  (211529, 50353)\t0.20754518276223055\n",
      "  (211529, 49943)\t0.14922044812769453\n",
      "  (211529, 19108)\t0.4096783539112134\n",
      "  (211529, 19106)\t0.3105069417998444\n",
      "  (211529, 1509)\t0.25939175576791823\n",
      "  (211529, 1508)\t0.2592624622522927\n"
     ]
    }
   ],
   "source": [
    "print(df['text'])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fc17e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "a=warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0557fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         text  polarity sentiment\n",
      "0       eat sour harm covid19 -0.150000  Negative\n",
      "1       covid19 suck job gone  0.000000   Neutral\n",
      "2       depress see peopl die -0.066667  Negative\n",
      "3  happi famili lockdown time  0.000000   Neutral\n",
      "No. of feature_words:  27\n",
      "  (0, 23)\t0.388614292631317\n",
      "  (0, 22)\t0.388614292631317\n",
      "  (0, 13)\t0.388614292631317\n",
      "  (0, 12)\t0.388614292631317\n",
      "  (0, 6)\t0.388614292631317\n",
      "  (0, 5)\t0.388614292631317\n",
      "  (0, 0)\t0.3063879719831814\n",
      "  (1, 25)\t0.388614292631317\n",
      "  (1, 24)\t0.388614292631317\n",
      "  (1, 15)\t0.388614292631317\n",
      "  (1, 14)\t0.388614292631317\n",
      "  (1, 9)\t0.388614292631317\n",
      "  (1, 1)\t0.388614292631317\n",
      "  (1, 0)\t0.3063879719831814\n",
      "  (2, 21)\t0.3779644730092272\n",
      "  (2, 20)\t0.3779644730092272\n",
      "  (2, 19)\t0.3779644730092272\n",
      "  (2, 18)\t0.3779644730092272\n",
      "  (2, 4)\t0.3779644730092272\n",
      "  (2, 3)\t0.3779644730092272\n",
      "  (2, 2)\t0.3779644730092272\n",
      "  (3, 26)\t0.3779644730092272\n",
      "  (3, 17)\t0.3779644730092272\n",
      "  (3, 16)\t0.3779644730092272\n",
      "  (3, 11)\t0.3779644730092272\n",
      "  (3, 10)\t0.3779644730092272\n",
      "  (3, 8)\t0.3779644730092272\n",
      "  (3, 7)\t0.3779644730092272\n"
     ]
    }
   ],
   "source": [
    "predict_ip = \"eating sour is #harmful during covid-19\"\n",
    "predf = pd.DataFrame()\n",
    "predf['text'] = [predict_ip,\"covid19 sucks job gone\",\"depression while seeing people die\",\"happy to be with family at lockdown time\"]\n",
    "\n",
    "predf.text = predf['text'].apply(data_processing)\n",
    "\n",
    "stemming_frame(predf['text'])\n",
    "\n",
    "predf['polarity'] = predf['text'].apply(polarity)\n",
    "\n",
    "predf['sentiment'] = predf['polarity'].apply(sentiment)\n",
    "\n",
    "predf = predf.drop_duplicates('text')\n",
    "print(predf)\n",
    "\n",
    "vectoriser1 = TfidfVectorizer(ngram_range=(1,2)).fit(predf['text'])\n",
    "print('No. of feature_words: ', len(vectoriser1.get_feature_names()))\n",
    "\n",
    "\n",
    "Xpred = predf['text']\n",
    "Ypred = predf['sentiment']\n",
    "Xpred = vectoriser1.transform(Xpred)\n",
    "\n",
    "print(Xpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f503d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 27\n",
      "\n",
      "features:\n",
      " ['covid19' 'covid19 suck' 'depress' 'depress see' 'die' 'eat' 'eat sour'\n",
      " 'famili' 'famili lockdown' 'gone' 'happi' 'happi famili' 'harm'\n",
      " 'harm covid19' 'job' 'job gone' 'lockdown' 'lockdown time' 'peopl'\n",
      " 'peopl die' 'see' 'see peopl' 'sour' 'sour harm' 'suck' 'suck job' 'time']\n"
     ]
    }
   ],
   "source": [
    "feature_names1 =vectoriser1.get_feature_names_out()\n",
    "print(\"Number of features: {}\\n\".format(len(feature_names1)))\n",
    "print(\"features:\\n {}\".format(feature_names1[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2021ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211530, 803546) (211530,) (4, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape,Xpred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f6e9912",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 27 features, but LogisticRegression is expecting 803546 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11656\\3041112978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlogreg_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlogreg_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogreg_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy: {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogreg_acc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 27 features, but LogisticRegression is expecting 803546 features as input."
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, Y)\n",
    "logreg_pred = logreg.predict(Xpred)\n",
    "logreg_acc = accuracy_score(logreg_pred, ypred)\n",
    "print(\"Test accuracy: {:.2f}%\".format(logreg_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b801a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64134c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = SVCmodel.predict(x_test)\n",
    "svc_acc = accuracy_score(svc_pred, y_test)\n",
    "print(\"test accuracy: {:.2f}%\".format(svc_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161612c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780511d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3bc44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
